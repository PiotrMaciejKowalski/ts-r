---
title: "Modele ARIMA"
author: "Sandra Sobór"
date: "9 kwietnia 2019"
output: html_document
---

Pierwszym zadaniem jest stworzenie wykresów ACF i PACF a nastęnie trzech modeli ARIMA.
Standardowo zaczniemy od wczytania naszych danych, zajmiemy się kursami z godziny 8:00 i dodatkowo zmienimy format kolumny z data, zapiszemy również dane w formacie stosownym dla szeregów czasowych proponowanym przez R. Załadowane zostaną również odpowiednie pakiety.

```{r warning = FALSE, message = FALSE}
library(forecast)
library(dplyr)
data_all <- read.csv2("ssobor-data.csv")
data_g <- data_all[data_all$godzina == 80000, ]
new_data <- as.Date(as.character(data_g$data), format = "%Y%m%d")
data_g$data = new_data
data <- ts(data_g$zamkniecie, frequency = 1)
```

Skoro nasze dane są już w przyjaznym formacie możemy stworzyć wykresy. 

```{r warning = FALSE}
tsdisplay(data)
```

## Model AR

Na podstawie pierwszego wykresu PACF możemy zauważyć, że odpowiedni dla danych będzie model AR(1), gdyż zaledwnie jeden słupek wystaje ponad nasz pas oznaczony niebieskimi przerywanymi liniami. 

```{r warning = FALSE}
ar <- Arima(data, order = c(1, 0, 0))
summary(ar)
```

## Model MA

Wykres ACF pokazuje nam jedynie, że szereg nie jest stacjonarny. Nie sugeruje nam on parametru dla modelu średniej kroczącej. Wykorzystajmy zatem komputer do znalezienia odpowiedniego parametru.

```{r warning = FALSE}
ma <- auto.arima(data, d = 0, max.p = 0)
summary(ma)
```

## Model ARIMA

Jako ostatni trzeci model, wykorzystamy model ARIMA, który łączy oba powyższe podejścia. Wyniki powinny być lepsze.

```{r warning = FALSE}
arima <- auto.arima(data)
summary(arima)
```

##Predykcja

Analizując trzy powyższe modele widzimy, że najlepiej radzą sobie AR i ARIMA. Można było spodziewać się tego już na początku, gdyż wykres ACF zupełnie nie sugerował żadnych współczynników. Stąd do predykcji wykorzystamy model AR(1) i ARIMA(1,1,1). Zacznijmy od podziału danych na zbiór uczący i testowy. Stworzymy prognozę na ostatnie 30 dni.

```{r}
n <- length(data_g$zamkniecie)
h <- 30
data_u <- ts(data_g$zamkniecie[1:(n - h)], frequency = 1)
r_values <- data_g$zamkniecie[(n - h + 1):n]
data_test <- ts(r_values, frequency = 1)
```

Stwórzmy teraz prognozy dla dwóch wybranych modeli.

```{r}
ar_u <- Arima(data_u, order = c(1, 0, 0))
data_u_fc1 <- forecast(ar_u, h = h)

arima_u <- Arima(data_u, order = c(1, 1, 1))
data_u_fc2 <- forecast(arima_u, h = h)

```

Skoro mamy już stworzone prognozy, to spójrzmy teraz na wykresy pokazujące prognozy jak i wartości rzeczywiste:

```{r}
plot(data_u_fc1, main = "Prognoza poprzez model AR(1,0,0)", xlab = "Dzień", ylab = "Kurs zamknięcia o 8:00")
lines(x = (n - h + 1):n, y = r_values)
```


```{r}
plot(data_u_fc2, main = "Prognoza poprzez model ARIMA(1,1,1)", xlab = "Dzień", ylab = "Kurs zamknięcia o 8:00")
lines(x = (n - h + 1):n, y = r_values)
```

Widzimy zatem, że model AR dokonał lepszej prognozy, ale żeby to potwierdzić policzymy błędy średniokwadratowe.

```{r}
bl_ar <- mean((data_u_fc1[["mean"]] - r_values) ^ 2)
bl_arima <- mean((data_u_fc2[["mean"]] - r_values) ^ 2)
bledy <- c("Błąd dla AR" = bl_ar, "Błąd dla ARIMA" = bl_arima)
bledy
```

Nasze przypuszczenie na podstawie wykresu zostało potwierdzone poprzez błędy kwadratowe. W tym przypadku model AR okazał się zdecydowanie bardziej odpowiedni.
